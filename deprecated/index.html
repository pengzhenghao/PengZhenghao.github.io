<!doctype html>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <title>PENG Zhenghao's Homepage</title>
    <meta name="author" content="PENG Zhenghao">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1,maximum-scale=1,user-scalable=no">
    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Simonetta:400,900|Balthazar">
    <link rel="stylesheet" type="text/css" href="styles.css">
    <link rel="stylesheet" type="text/css" href="responsive.css">
    <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
    <![endif]-->
</head>

<body>

<h3 style="padding-left: 0em;margin: 0em 50px;
    padding: 0px 40px; 
    padding-top: 35px; 
    min-width: 260px; ">
    <div style="letter-spacing: 0.1em;font-style: italic;text-align: center;padding-top: 0em;padding-bottom: 1em;color:#c2c2c2;font-size: 0.9em;">
        This page is updated on July 26, 2021.
    </div>
</h3>

<div id="w" itemscope itemtype="http://schema.org/Person">
    <header class="clearfix">
        <div id="info">
            <h1><span itemprop="name">PENG&nbsp&nbsp;Zhenghao&nbsp;&nbsp;|&nbsp;</span>
                <img class="sign" src="images/sign.png" alt="" itemprop="image" align="top"/></h1>
            <div id="photo">
                <img src="images/pengzhenghao_photo_2021.jpg" alt="PENG Zhenghao resume photo avatar" itemprop="image"
                     align="right"/>
            </div>

            <div class="topcontent">
                <!-- <small>Pronounciation of my name: </small> -->
                <small><a
                        href="https://github.com/pengzhenghao/pengzhenghao.github.io/raw/master/cv_pengzhenghao_20210726.pdf">Download
                    My CV (Updated on July 26, 2021)</a></small>
                <small><a href="mailto:pengzh@ie.cuhk.edu.hk" itemprop="email">pengzh@ie.cuhk.edu.hk</a></small>
                <small><a href="https://space.bilibili.com/442318796" itemprop="url">Bilibili</a> &bull; <a
                        href="https://github.com/pengzhenghao" itemprop="url">Github</a> &bull; <a
                        href="https://scholar.google.com/citations?user=JZ8ws6IAAAAJ">Google Scholar</a></small>
            </div>
        </div>

    </header>

    <!--
            <section>
                <h2>Research Interests</h2>
                <h4>Multi-agent Reinforcement Learning</h4>
                <ul>
                    <li>How to cope with cooperative and competitive environment? </li>
                    <li>Is there any good way to set the goal rather than defining the reward function?</li>
                    <li>What is hidden beneath which undermine the robustness of RL system?</li>
                    <li>
                    How to increase the sample-efficiency?</li>
                </ul>
                <h4>Video Action Detection</h4>
                <ul>
                    <li>
                        How to improve the accuracy of classification, and the accuracy of temporal localization?
                    </li>
                    <li>
                    How to leverage few-shot learning and weakly-supervised learning in this field?
                    </li></ul>
                <h4>Machine Learning Theory</h4>
                <ul>
                    <li>
                        How to accelerate Neural network computing?</li>
                    <li>
                        How to interpret what a neural network does? Why it perform well or badly?
                    </li>
                    <li>
                        Is there any relationship between control theory and machine learning?
                    </li>
                            </ul>
                <small style="color: #CC0066;padding-top: 1.4em; text-align: center"><b>Finding the Newton's Three Laws in Machine Learning is my final goal!</b></small>
            </section> -->


    <section id="education">
        <h2>Education</h2>

        <div>
            <h3>
                <div class="caption">August 2019 - Present</div>
            </h3>
            <h4>Chinese University of Hong Kong</h4>
        </div>
        <ul>
            <li>
                PhD candidate at Information Engineering Department.
            </li>
            <li>
                Supervised by <a href="http://bzhou.ie.cuhk.edu.hk">Professor Zhou Bolei</a>.
            </li>
        </ul>

        <div>
            <h3>
                <div class="caption">September 2015 - July 2019</div>
            </h3>
            <h4>Shanghai Jiao Tong University</h4>
        </div>
        <ul>
            <li>Supervised by <a href="http://www.cs.sjtu.edu.cn/~jiangli/">Professor Jiang Li</a> at Advanced Computer
                Architecture Laboratory.
            </li>
        </ul>
        <ul>
            <li>
                Senior Student in Naval Architecture and Ocean Engineering.
            </li>
            <li>
                Member of Zhiyuan Honors Program (Top 10% students at whole university).
            </li>
            <li>
                Won Zhiyuan Honors Scholarship for 4 consecutive years.
            </li>
        </ul>

        <div>
            <h3>
                <div class="caption">June 2018 - September 2018</div>
            </h3>
            <h4>
                Shenzhen Institutes of Advanced Technology (SIAT), CAS
            </h4>
        </div>
        <ul>
            <li>
                Research intern at Multimedia Research Center, under the supervision of <a
                    href="http://mmlab.siat.ac.cn/yuqiao/">Professor Qiao Yu</a>
            </li>
        </ul>

        <div>
            <h3>
                <div class="caption">July 2017 - August 2017</div>
            </h3>
            <h4>University of California, Berkeley</h4>
        </div>
        <ul>
            <li>
                Summer session.
            </li>
        </ul>
    </section>

    <section id="research">
        <h2>Selected Projects</h2>


        <div class="project">
            <div class="projectimage">
                <a href="" target="_blank">
                    <img src="images/cover_egpo.png">
                </a>
            </div>
            <h4>Safe RL System via Expert in the Loop</h4>
            <ul>
                The Expert Guided Policy Optimization (EGPO) framework incorporates the guardian mechanism in the
                interaction of agent and environment to ensure safe and efficient exploration.
                <br>
                Paper [9]
            </ul>
        </div>

        <div class="project">
            <div class="projectimage">
                <a href="" target="_blank">
                    <img src="images/cover_copo.png">
                </a>
            </div>
            <h4>Simulating Realistic Traffic Flow via Multi-agent RL</h4>
            <ul>
                We develop a novel MARL method called Coordinated Policy Optimization (CoPO) to incorporate social
                psychology principle to learn neural controller for a population of autonomous driving vehicles.
                <br>
                Paper [8]
            </ul>
        </div>

        <div class="project">
            <div class="projectimage">
                <a href="https://decisionforce.github.io/pgdrive/" target="_blank">
                    <img src="images/cover_pgdrive.png">
                </a>
            </div>
            <h4>Autonomous Driving Simulator: PGDrive</h4>
            <ul>
                An open-ended and highly customizable driving simulator with the power of generating infinite driving
                scenes. <br>
                <a href="https://arxiv.org/pdf/2012.13681.pdf" target="_blank">Paper</a> [6],
                <a href="https://github.com/decisionforce/pgdrive" target="_blank">Code</a>,
                <a href="https://decisionforce.github.io/pgdrive/" target="_blank">Webpage</a> <br>
            </ul>
        </div>

        <div class="project">
            <div class="projectimage">
                <a href="" target="_blank">
                    <img src="images/cover_depo.png">
                </a>
            </div>
            <h4>Efficient Asynchronous Reinforcement Learning</h4>
            <ul>
                Ensemble Policy Optimization (EPO) framework trains multiple heterogeneous policies simultaneously
                solving the same task while maintaining the diversity of the ensemble.
                <br>
                <a href="https://arxiv.org/pdf/2006.07781.pdf" target="_blank">Paper</a> [5]
            </ul>
        </div>

    </section>


    <section>
        <h2>Research Papers</h2>
        <ul>
            <li>
                [9]
                <b>Zhenghao Peng*</b>, Quanyi Li*, Chunxiao Liu, and Bolei Zhou.
                Safe driving via expert guided policy optimization.
                (Submitted to CoRL 2021)
            </li>
            <li>
                [8]
                <b>Zhenghao Peng</b>, Quanyi Li, Chunxiao Liu, and Bolei Zhou.
                Learning to simulate self-driven particles system with coordinated policy optimization.
                (Submitted to NeurIPS 2021)
            </li>
            <li>
                [7]
                Hao Sun, Ziping Xu, Meng Fang, <b>Zhenghao Peng</b>, Jiadong Guo, Bo Dai, and Bolei Zhou.
                Safe exploration by solving early terminated mdp.
                (arXiv preprint)
                [<a href="https://arxiv.org/pdf/2107.04200.pdf">PDF</a>]
            </li>
            <li>
                [6]
                Quanyi Li*, <b>Zhenghao Peng*</b>, Qihang Zhang, Chunxiao Liu, and Bolei Zhou.
                Improving the generalization of end-to-end driving through procedural generation. (arXiv preprint)
                [<a href="https://arxiv.org/pdf/2012.13681">PDF</a>]
            </li>
            <li>
                [5]
                <b>Zhenghao Peng</b>, Hao Sun, and Bolei Zhou. Non-local policy optimization via
                diversity-regularized collaborative exploration. (arXiv preprint)
                [<a href="https://arxiv.org/pdf/2006.07781.pdf">PDF</a>]
            </li>
            <li>
                [4]
                Hao Sun, <b>Zhenghao Peng</b>, Bo Dai, Jian Guo, Dahua Lin, and Bolei Zhou. Novel policy seeking
                with constrained optimization. (arXiv preprint)
                [<a href="https://arxiv.org/pdf/2005.10696.pdf">PDF</a>]
            </li>
            <li>
                [3]
                Hao Sun, Jiankai Sun, <b>Zhenghao Peng</b>, Dahua Lin, and Bolei Zhou. Learning with identity and
                uniqueness through social constraint. (NeurIPS 2019 Deep RL Workshop)
            </li>
            <li>
                [2]
                Zhuoran Song, Dongyu Ru, Ru Wang, Hongru Huang, <b>Zhenghao Peng</b>, Jing Ke, Xiaoyao Liang, and Li
                Jiang. Approximate random dropout. (DATE 2020)
                [<a href="https://arxiv.org/pdf/1805.08939.pdf">PDF</a>]
            </li>
            <li>
                [1]
                <b>Zhenghao Peng</b>, Xuyang Chen, Chengwen Xu, Naifeng Jing, Xiaoyao Liang, Cewu Lu, and Li Jiang.
                Axnet: Approximate computing using an end-to-end trainable neural network. (ICCAD 2018)
                [<a href="https://arxiv.org/pdf/1807.10458.pdf">PDF</a>]
            </li>
        </ul>
    </section>

    <section>
        <h2>Miscellaneous</h2>
        <h4>Programming Languages</h4>
        <ul style="list-style: none;">
            <li>Python, Matlab, HTML, CSS, C++, etc.</li>
        </ul>
        <h4>ML Frameworks</h4>
        <ul style="list-style: none;">
            <li>Ray, RLLib, TensorFlow, PyTorch, Keras etc.</li>
        </ul>
        <h4>Productivity Tools</h4>
        <ul style="list-style: none;">
            <li>Roam Research, macOS, Git, PyCharm, Zotero, MindNode, Markdown, draw.io, TickTick, etc.</li>
        </ul>
        <h4>Skills</h4>
        <ul style="list-style: none;">
            <li>Git, LaTeX, PyCharm, Keynote, Photoshop, Final Cut, Cantonese, etc.</li>
        </ul>
        <h4>Languages</h4>
        <ul style="list-style: none;">
            <li>Mandarin Chinese (Native), Cantonese (Native), English (TOEFL 100), Teochew Dialect (Only
                Listening)
            </li>
        </ul>
        <h4>Hobbies</h4>
        <ul>
            <li style="list-style: none;">
                Genshin Impact (原神),
                Billiards, Badminton,
                Film Criticism,
                Science Fiction,
                Photography,
                Jogging, etc.
            </li>
        </ul>
    </section>

</div>
</body>
</html>